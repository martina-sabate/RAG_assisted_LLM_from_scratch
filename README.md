# Your Study Assistant, built from scratch
Build Your Own RAG-Assisted Large Language Model (LLM) â€“ Step-by-Step Guide (beginner friendly)

ðŸ“– A Practical AI Tutorial for anyone getting started with AI and LLMs

This repository provides a step-by-step guide on how to apply Retrieval-Augmented Generation (RAG) to a Large Language Model (LLM) to ground your model's results on literature of your choice. We will code this from scratch using open-source tools. By the end of this tutorial, you will understand how to:

- Implement RAG architecture to enhance LLMs with external knowledge.
- Connect LLMs (like OpenAIâ€™s GPT) with document search capabilities.
- Deploy a functional AI model with Streamlit for easy interaction.

ðŸ’¡ The Use Case: 

AI Assistant for Research Papers To make this tutorial practical, we apply the RAG model to help students and researchers quickly understand complex research papers. Upload any paper you need to read and retrieve information from it / get summaries in seconds.

And remember, this technique can be used for any AI-powered document assistant!

ðŸ“Œ Tech Stack & Concepts You'll Learn

- Retrieval-Augmented Generation (RAG)
- HuggingFace Transformers Framework
- Prompt Engineering concepts
- Streamlit

Step by step instructions in 'RAG_assisted_LLM.ipynb' file.
