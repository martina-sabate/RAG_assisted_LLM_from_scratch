{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa252f14-c3d7-462c-8a63-b733136636d6",
   "metadata": {},
   "source": [
    "# Step 1: Setting up the environment\n",
    "\n",
    "#### To create and activate a virtual environment, run on your terminal:\n",
    "\n",
    "**Windows:**\n",
    "\n",
    "\n",
    "```\n",
    "python -m venv venv\n",
    "```\n",
    "```\n",
    "venv\\Scripts\\Activate\n",
    "```\n",
    "\n",
    "**macOS/Linux:**\n",
    "\n",
    "```\n",
    "python3 -m venv venv\n",
    "```\n",
    "\n",
    "```\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "#### After the environment is activated, install the requirements:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368ccd1-8969-49b2-93c0-f3af7b30e185",
   "metadata": {},
   "source": [
    "# Step 2: Pre-processing the document\n",
    "\n",
    "#### What you will need:\n",
    "1. PDF Document (skin cancer detection paper in my case)\n",
    "2. Embedding model (I am using Sentence-Bert)\n",
    "\n",
    "As described in the Readme file, the aim of this tutorial is to build a RAG-assisted LLM that can retrieve information from research papers, helping students and researcher get a quicker understanding of the paper. I will be using the paper *Skin Cancer Detection using ML Techniques* <sup>1</sup> for this example.  Feel free to use any paper you would like to retrieve information from, the same steps will apply to any paper / book. All you need to do is download it in pdf format and add your file path to the variable 'path'.  \n",
    "\n",
    "To pre-process the PDF document, we will use an embedding model. \n",
    "\n",
    "#### ‚ö†Ô∏è Now, what does ‚Äúembedding‚Äù mean in AI?\n",
    "\n",
    "In this tutorial, we are trying to get our AI model to understand a paper (complex text data). The problem is, our model can only understand numbers. That is where embeddings come in.\n",
    "\n",
    "> An embedding is a way of representing complex data (like words or images) as a list of numbers ‚Äî called a vector ‚Äî in such a way that the relationships between items are preserved.\n",
    "\n",
    "\n",
    "#### Let‚Äôs dive into that:\n",
    "\n",
    "Think of each item (a word, an image, a sentence) as a point in space - a location on a map. The closer two points are, the more related their meanings are.\n",
    "\n",
    "For example:\n",
    "\n",
    "- The word ‚Äúcat‚Äù will be close to ‚Äúdog‚Äù.\n",
    "\n",
    "- The word ‚Äúcar‚Äù will be far away from ‚Äúbanana‚Äù.\n",
    "\n",
    "That‚Äôs because in real life, cats and dogs are similar (both animals, pets), while a car and a banana are not.\n",
    "\n",
    "So embeddings help us map meaning into a mathematical space.\n",
    "\n",
    "#### üßê What is an embedding model?\n",
    "\n",
    "An embedding model is an AI model that has learned how to take something complex ‚Äî like a sentence ‚Äî and turn it into a vector (a list of numbers) that captures its meaning.\n",
    "\n",
    "Different embedding models specialize in different kinds of data. The table below shows some examples of open-source embedding models for different use cases:\n",
    "\n",
    "\n",
    "| Data Type         | Embedding model examples    | What do they capture? |\r\n",
    "|-------------------|-----------------------------|-------------------------------\n",
    "| Words | Word2Vec, GloVe, FastText | Word meanings, analogies, syntactic similarity |\n",
    "| Sentences / Text | Sentence-BERT (SBERT), Instructor, E5 | Semantic similarity between sentences/documents |\n",
    "| Images              |  DINO, OpenCLIP   | Visual concepts, cross-modal (image-text) meaning   |\n",
    "| Audio               |  Wav2Vec 2.0, Whisper  | Speech content, audio features   |\n",
    "| Code | CodeBERT, GraphCodeBERT | Code syntax and semantics |  \n",
    "\n",
    "In this tutorial we are looking to read PDF documents, therefore, we need a model that embeds data based on semantic similarity. I have chosen Sentence-BERT, but it is interchangable for any sentence / text embedding model. Once you have build your own RAG-assisted LLM, you can experiment with different models and decide what works best for you.\n",
    "\n",
    "#### Now that we know how the data pre-processing will work, let's get started!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "< |\r\n",
    "\n",
    "\n",
    "\n",
    "<sup>1</sup> M. Vidya and M.V. Karki \"Skin Cancer Detection using Machine Learning Techniques\", 2020 IEEE International Conference on Electronics, Computing and Communication Technologies, Bangalore, India, 2020, pp. 1-5, doi 10.1109/CONECCT50063.2020.9198489.98489. \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f0ab73-6e6a-4fa7-9367-347cf32452cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frontend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Note: tqdm is used to obtain a progress bar from any loop you run with it\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get PDF path \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Change this variable to your pdf path______________________________\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fitz\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'frontend'"
     ]
    }
   ],
   "source": [
    "# Import relevant modules\n",
    "import os\n",
    "import requests\n",
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "#Note: tqdm is used to obtain a progress bar from any loop you run with it\n",
    "\n",
    "# Get PDF path \n",
    "# Change this variable to your pdf path______________________________\n",
    "pdf_path = r\"G:\\My Drive\\feines 2025\\MS Imaging paper\\to submit.pdf\"\n",
    "#____________________________________________________________________\n",
    "\n",
    "# Check that the path exists\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"PDF file '{pdf_path}' exists.\")\n",
    "else:\n",
    "    print(f\"PDF file '{pdf_path}' does not exist\")\n",
    "\n",
    "# Open the PDF file\n",
    "document = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3e98c-708c-47a9-800d-5be7642239ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to clean text\n",
    "def format_pdf(pdf_text: str) -> str: # REMOVE -> STR ???????????????????????\n",
    "  \"\"\"Use this function for any formatting you want to apply to the text prior to embedding.\n",
    "  Input: PDF text\n",
    "  Output: PDF text with \\n replaced for a space\"\"\"\n",
    "  formatted_pdf = pdf_text.replace(\"\\n\", \" \").strip()\n",
    "  # add any other formatting features here\n",
    "  return formatted_pdf\n",
    "\n",
    "# Define helper function to open and read pdfs\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "  doc = fitz.open(pdf_path)\n",
    "  output = [] #empty list that will be filled with info in the pdf's pages\n",
    "  # Get each page (enumerate is used to number the pages) and apply pre-process\n",
    "  # helper function\n",
    "  for page_number, page in tqdm(enumerate(doc)):\n",
    "    text = page.get_text()\n",
    "    text = format_pdf(text=text)\n",
    "    output.append({\"page_number\": page_number - 41,         #page number\n",
    "                   \"page_char_count\": len(text),            #chars in the page\n",
    "                   \"page_word_count\": len(text.split(\" \")), #words in the page\n",
    "                   \"page_sentence_count_raw\": len(text.split(\". \")), #sentences\n",
    "                   \"page_token_count\": len(text) / 4,       #tokens in the page\n",
    "                   \"text\": text                             #text in the page\n",
    "                   # Reminder: 'Hello, World!' has 4 tokens: 'Hello', ',',\n",
    "                   # 'World', and '!'. 1 token ~= 4 char on average.\n",
    "                   })\n",
    "  return output\n",
    "\n",
    "# Apply open and read helper function to pdf and display pages 1-3\n",
    "output = open_and_read_pdf(pdf_path=pdf_path)\n",
    "output[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
